{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers (SBERT) with PyTorch: Similarity and Semantic Search\n",
    "\n",
    "**Youtube Link:** https://www.youtube.com/watch?v=nZ5j289WN8g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics/Displays:\n",
      "\n",
      "    Intel UHD Graphics 630:\n",
      "\n",
      "      Chipset Model: Intel UHD Graphics 630\n",
      "      Type: GPU\n",
      "      Bus: Built-In\n",
      "      VRAM (Dynamic, Max): 1536 MB\n",
      "      Vendor: Intel\n",
      "      Device ID: 0x3e9b\n",
      "      Revision ID: 0x0002\n",
      "      Automatic Graphics Switching: Supported\n",
      "      gMux Version: 5.0.0\n",
      "      Metal Support: Metal 3\n",
      "\n",
      "    Radeon Pro 560X:\n",
      "\n",
      "      Chipset Model: Radeon Pro 560X\n",
      "      Type: GPU\n",
      "      Bus: PCIe\n",
      "      PCIe Lane Width: x8\n",
      "      VRAM (Total): 4 GB\n",
      "      Vendor: AMD (0x1002)\n",
      "      Device ID: 0x67ef\n",
      "      Revision ID: 0x00c2\n",
      "      ROM Revision: 113-C980AL-075\n",
      "      VBIOS Version: 113-C97501U-005\n",
      "      EFI Driver Version: 01.A1.075\n",
      "      Automatic Graphics Switching: Supported\n",
      "      gMux Version: 5.0.0\n",
      "      Metal Support: Metal 2\n",
      "      Displays:\n",
      "        Color LCD:\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2880 x 1800 Retina\n",
      "          Framebuffer Depth: 24-Bit Color (ARGB8888)\n",
      "          Main Display: Yes\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Automatically Adjust Brightness: No\n",
      "          Connection Type: Internal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! system_profiler SPDisplaysDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! system_profiler SPDisplaysDataType > gpu_info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.0\n",
      "IPython version      : 8.26.0\n",
      "\n",
      "numpy       : 1.26.4\n",
      "pandas      : 2.2.2\n",
      "torch       : 2.2.2\n",
      "transformers: 4.44.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device='mps')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the maximum number of characters/tokens that the model can take\n",
    "model.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\",\n",
    "    \"One of the biggest Bull traps I've ever seen.\",\n",
    "    \"How I sleep knowing etherum is going to 10k in 2023\",\n",
    "    \"Bitcoin is a scam\",\n",
    "    \"IS THE $BTC BOTTOM IN? Are you team BULL or team BEAR? Do you have the DATA to prove your point??\",\n",
    "    \"I will stop bragging about calling the top when I start bragging about calling the bottom. #bitcoin\",\n",
    "    \"First powerlifting meet of the year and a new squat PR!!\",\n",
    "    \"On January 9th, 2023, the American Academy of Pediatrics published new guidelines treating obesity in children and adolescents.\",\n",
    "    \"What's worse, someone dropping the bar from the top of a deadlift or not putting their shopping cart away?\",\n",
    "    \"The sport of powerlifting includes squat bench and deadlift. But the concept of powerlifting is Force= Mass x Acceleration.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0671,  0.0218, -0.0305,  ..., -0.0016, -0.0345, -0.0030],\n",
       "        [-0.0055, -0.0304,  0.0158,  ...,  0.0144,  0.0186,  0.0054],\n",
       "        [-0.0240,  0.0824, -0.0400,  ...,  0.0156, -0.0155, -0.0518],\n",
       "        ...,\n",
       "        [ 0.0721,  0.0978,  0.0143,  ..., -0.0074, -0.0561, -0.0374],\n",
       "        [-0.0283,  0.0284,  0.0064,  ..., -0.0165, -0.0167, -0.0041],\n",
       "        [-0.0032, -0.0487,  0.0164,  ..., -0.0162,  0.0181, -0.0025]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(corpus, show_progress_bar=True, convert_to_tensor=True)\n",
    "corpus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How high will bitcoin go?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.6440e-02,  3.2738e-02, -3.3854e-02,  2.5782e-03,  4.6909e-02,\n",
       "        -1.0622e-02, -4.9374e-02, -2.5929e-02,  4.1010e-02, -3.7868e-03,\n",
       "         8.4012e-03,  4.4253e-03, -3.8478e-02,  1.1281e-01,  6.4806e-03,\n",
       "        -4.7081e-02,  4.1241e-02, -2.2989e-02,  1.0063e-02, -4.0438e-02,\n",
       "        -1.6192e-02, -5.6703e-02,  4.1887e-02, -2.9924e-03, -2.0055e-02,\n",
       "         9.2723e-03,  2.3443e-02,  4.1819e-02, -3.8099e-02, -5.1336e-03,\n",
       "        -7.1172e-02, -2.7961e-02, -4.7446e-02,  5.1631e-02,  1.4831e-06,\n",
       "        -4.5730e-02,  6.1654e-04,  3.3853e-02, -1.7810e-02, -8.5618e-02,\n",
       "        -8.5605e-02, -2.6440e-02, -9.6930e-03,  1.9836e-02, -1.2204e-02,\n",
       "         2.4640e-02, -4.3704e-02,  2.7261e-02, -2.3189e-02,  2.2393e-02,\n",
       "        -2.7534e-03, -6.5008e-02,  5.6481e-02,  9.2656e-03,  2.6180e-02,\n",
       "        -4.4296e-02,  1.7331e-02,  5.5997e-02, -7.0871e-03,  3.7933e-02,\n",
       "         2.9549e-03,  2.5222e-02,  1.5936e-02, -5.9650e-04,  1.3558e-02,\n",
       "         2.8841e-02,  1.6692e-02,  3.8148e-02, -3.1789e-02, -3.3957e-02,\n",
       "        -3.3201e-02, -1.7019e-02,  4.4136e-03,  3.7717e-02,  5.2867e-03,\n",
       "        -6.2512e-03, -3.6055e-03, -4.5571e-02,  2.0250e-02,  1.7175e-02,\n",
       "         7.6862e-02, -4.1048e-02, -4.9486e-02,  1.4573e-02,  1.8017e-02,\n",
       "         3.2681e-02, -5.6502e-02, -3.8739e-03,  4.9458e-02, -1.1678e-02,\n",
       "         2.0439e-02,  6.5270e-02,  4.9826e-03, -3.5808e-02, -5.2198e-02,\n",
       "         1.9563e-02, -9.0123e-03, -9.9799e-03,  1.9671e-02, -9.1783e-02,\n",
       "        -2.2492e-02,  1.0825e-02,  4.0970e-02,  5.9488e-02, -6.5868e-03,\n",
       "        -7.3048e-02, -5.8260e-02, -4.4448e-02,  3.9437e-02,  1.6280e-02,\n",
       "         3.1535e-02, -8.0148e-03, -1.5143e-02, -4.5344e-02,  3.2621e-03,\n",
       "         4.4056e-03,  4.5443e-03, -2.9037e-02,  2.8718e-02, -1.1680e-02,\n",
       "         1.2146e-02,  1.3644e-02, -1.2870e-02,  1.7971e-03,  2.0425e-02,\n",
       "         3.2446e-02, -5.5981e-02, -9.9222e-03,  3.4120e-03,  1.0469e-02,\n",
       "         2.7498e-02, -1.9935e-02,  3.0793e-02,  2.8888e-02, -1.6614e-02,\n",
       "         3.4250e-02,  8.5352e-03, -6.1517e-03,  5.5369e-03, -1.7562e-02,\n",
       "        -6.1081e-03,  4.6465e-02,  2.4647e-03, -2.2555e-03, -1.4111e-01,\n",
       "         3.2599e-02, -2.1998e-02,  4.7043e-02, -1.7743e-02, -2.8326e-02,\n",
       "        -3.6344e-02,  1.6112e-02, -1.5428e-02, -8.3630e-03,  6.2694e-02,\n",
       "         4.5439e-03, -5.8445e-02, -6.4028e-02,  2.1694e-04,  6.8303e-02,\n",
       "         5.3727e-03, -4.8470e-02,  6.2956e-03,  4.7871e-02, -5.2611e-02,\n",
       "        -1.2011e-02,  2.5622e-02,  2.0417e-02,  3.6674e-02, -3.2218e-03,\n",
       "        -6.3806e-02,  1.8741e-02,  4.1256e-02, -3.8566e-02,  4.2114e-02,\n",
       "        -4.3543e-02, -7.7714e-02, -3.0182e-03, -2.4537e-02, -5.8310e-03,\n",
       "        -5.1550e-03, -1.2863e-01, -4.3455e-02,  1.0888e-02,  1.5289e-02,\n",
       "         7.9717e-03,  6.2600e-02, -6.9792e-02, -3.6030e-02, -1.7051e-02,\n",
       "        -3.4110e-02, -1.4722e-02, -4.5174e-03, -6.1440e-02, -2.4981e-03,\n",
       "        -3.8990e-02, -5.1408e-02, -9.5005e-03,  5.0508e-04,  6.8832e-02,\n",
       "         1.2401e-02,  2.7862e-03,  6.1732e-02, -7.4072e-02,  2.7679e-02,\n",
       "         1.9081e-02,  8.4000e-02, -1.0736e-04, -1.8010e-03, -3.4682e-03,\n",
       "         6.2870e-03,  1.0409e-02, -5.7275e-03,  3.5745e-02,  4.4694e-02,\n",
       "         6.8462e-02, -2.0317e-02,  2.2219e-02,  3.1310e-02,  2.3064e-02,\n",
       "        -3.1893e-02,  3.0391e-02,  2.4442e-02, -4.9574e-03, -1.6574e-02,\n",
       "         1.5746e-02, -3.5361e-02,  1.6078e-02,  1.2805e-02, -3.9268e-03,\n",
       "        -2.7161e-02,  1.8610e-02,  4.0204e-02, -1.4507e-02, -5.3525e-02,\n",
       "        -3.6468e-02,  7.1591e-03,  3.6220e-02,  1.9440e-03, -2.6687e-02,\n",
       "        -3.9285e-03, -8.6630e-02,  1.8579e-02, -2.6158e-02,  2.5389e-02,\n",
       "        -1.9691e-02,  1.1632e-02, -7.2257e-03, -7.6238e-02,  4.9094e-03,\n",
       "         2.0954e-02,  5.4352e-02,  3.9112e-02,  1.8318e-02,  5.8461e-03,\n",
       "         1.2896e-02, -2.0186e-02,  2.5957e-02,  5.3622e-02,  1.7645e-02,\n",
       "        -3.5608e-02, -4.3495e-02, -2.9069e-02, -5.5217e-03,  6.2087e-03,\n",
       "        -4.3337e-02,  4.4430e-03, -2.4376e-02, -5.8566e-02, -1.6485e-02,\n",
       "         7.5358e-02, -3.4471e-02, -3.1102e-02, -1.1799e-02, -4.2504e-02,\n",
       "        -1.5802e-02, -3.0104e-04,  2.3170e-02, -5.7243e-03, -1.4955e-02,\n",
       "         7.3180e-02,  7.8110e-04, -3.0755e-02,  2.1715e-02,  3.0350e-04,\n",
       "        -9.7621e-03,  7.1949e-02,  1.5478e-02,  4.1345e-02,  1.3061e-02,\n",
       "        -3.4359e-02,  2.4182e-02, -3.0986e-02, -1.7130e-02,  4.6135e-02,\n",
       "         3.7664e-02,  1.9440e-02, -7.0279e-02,  8.6375e-03, -1.2925e-02,\n",
       "        -7.8845e-03,  3.0386e-02,  2.2319e-02,  1.8079e-02, -4.0957e-03,\n",
       "        -6.9498e-03,  1.1304e-02,  5.6829e-02, -3.0558e-02,  9.6919e-02,\n",
       "         2.1030e-02,  3.2370e-02, -1.1069e-02,  2.5698e-02, -1.4679e-02,\n",
       "        -7.0358e-02,  1.3897e-02,  5.6215e-02, -3.4894e-02,  4.4826e-02,\n",
       "         1.8845e-02, -2.7503e-02,  3.0337e-02, -2.6013e-03,  5.2561e-02,\n",
       "         6.6672e-02,  5.5980e-02,  3.0838e-03,  3.1092e-02,  2.9424e-03,\n",
       "         1.5554e-02, -3.3166e-02,  3.5477e-03,  1.8282e-02, -2.5118e-02,\n",
       "        -9.4694e-02, -3.2440e-02, -4.2791e-02, -5.3528e-02,  3.8850e-03,\n",
       "         1.0821e-03,  7.3460e-03, -9.6269e-03, -1.5025e-02, -3.4890e-02,\n",
       "        -1.4618e-02,  1.7903e-02,  4.1147e-02,  5.6654e-02, -3.9975e-02,\n",
       "        -1.2120e-02,  8.5288e-03,  1.5403e-02, -1.8263e-02,  4.7606e-03,\n",
       "         3.6203e-02,  1.7458e-02, -3.3518e-02, -3.5384e-02,  4.3042e-02,\n",
       "        -2.6903e-02,  1.8215e-02, -3.3407e-02,  6.2403e-02, -2.0699e-02,\n",
       "        -9.2782e-03,  2.7810e-02,  5.4889e-02,  3.4513e-03,  2.0309e-02,\n",
       "        -2.4136e-02,  4.4746e-02, -1.3252e-02,  3.5877e-02,  2.8353e-02,\n",
       "         3.9758e-02,  2.2231e-02, -8.4896e-03, -1.2486e-02,  2.2374e-03,\n",
       "         1.0789e-02, -3.2077e-02,  2.1989e-02, -1.6138e-02, -5.5092e-02,\n",
       "        -2.8389e-02,  5.2013e-03,  1.7508e-02, -5.6359e-02,  3.0531e-02,\n",
       "        -2.8118e-02,  6.5966e-02,  4.9468e-02, -2.1297e-02, -1.9812e-02,\n",
       "         6.1580e-02,  2.2598e-02, -5.5751e-02,  6.7667e-05,  8.2667e-03,\n",
       "         6.7533e-03, -3.6205e-02,  5.8532e-02,  9.3965e-02,  5.3725e-03,\n",
       "        -2.3378e-02,  6.4812e-02,  9.2874e-02, -4.5967e-02,  1.6676e-03,\n",
       "        -5.1720e-02,  5.6821e-03,  3.2837e-02, -2.0628e-02,  8.7154e-02,\n",
       "         3.4688e-02, -2.2743e-02, -1.4211e-02,  4.9265e-02, -3.9578e-02,\n",
       "         5.8588e-02,  2.1554e-02, -4.3793e-02,  3.9278e-02, -7.8330e-02,\n",
       "        -2.4559e-02, -4.4876e-02, -6.5179e-02, -1.8723e-02, -6.1020e-03,\n",
       "        -8.8227e-04, -1.6520e-02, -3.1764e-02,  9.3030e-02, -1.5769e-02,\n",
       "         4.7908e-02, -3.6933e-02,  2.4183e-02,  4.0530e-02,  1.4155e-02,\n",
       "         2.7836e-02, -2.6419e-02,  2.0762e-03, -3.6915e-03,  4.8491e-02,\n",
       "         6.3044e-02,  2.2222e-02,  2.4804e-02, -7.4650e-03, -1.7640e-03,\n",
       "         4.3927e-02, -7.8066e-02,  1.8425e-02,  6.4402e-02, -2.1445e-02,\n",
       "        -5.3551e-04, -1.0171e-02, -1.4563e-02,  1.4076e-03, -1.1565e-02,\n",
       "         2.4173e-04,  1.9781e-02, -3.4689e-02,  3.2353e-04, -2.2319e-02,\n",
       "        -1.7305e-03,  1.6081e-02,  1.0573e-02, -9.1727e-03,  2.4037e-03,\n",
       "         4.4548e-02, -3.4514e-02,  1.2993e-02, -8.1516e-03,  2.8991e-02,\n",
       "        -1.6264e-02, -8.3140e-02, -2.3088e-02, -2.8559e-03, -7.6741e-03,\n",
       "         8.0389e-03,  9.7007e-03, -2.2204e-02,  2.3054e-02, -4.9384e-03,\n",
       "        -2.4176e-02, -2.6649e-03,  4.9319e-03, -2.4388e-04, -3.2880e-02,\n",
       "         2.2568e-02, -1.9529e-02, -4.4392e-02,  4.1384e-02,  3.9662e-02,\n",
       "        -2.6291e-02, -1.7386e-02, -9.0536e-02, -1.0402e-01,  2.0893e-02,\n",
       "        -1.0881e-02, -1.3428e-02, -3.6393e-02, -4.9671e-02,  4.0106e-03,\n",
       "         5.2446e-02, -4.3366e-03,  5.3973e-02, -5.1692e-02, -2.2283e-02,\n",
       "         4.4728e-02,  1.7598e-02, -1.1248e-02, -3.6982e-02,  4.3613e-02,\n",
       "         7.3224e-02, -5.8099e-02,  6.2608e-02,  3.4938e-02, -3.0094e-04,\n",
       "         3.0570e-02,  5.1552e-03,  1.9558e-03, -6.8856e-03, -1.9927e-02,\n",
       "        -2.3433e-02, -2.7587e-03, -3.6015e-02,  3.5072e-02,  5.5105e-02,\n",
       "         4.5490e-02, -6.8845e-02,  1.6266e-02, -1.0487e-02,  1.4912e-02,\n",
       "         5.1353e-02, -3.2503e-02, -1.5512e-02,  3.1065e-02,  5.4468e-02,\n",
       "        -9.0410e-04,  1.6850e-03, -5.7989e-03,  1.9323e-02, -7.3187e-02,\n",
       "        -1.8910e-02,  3.8335e-03, -5.4189e-03, -2.5194e-02,  2.7040e-02,\n",
       "         4.4152e-02,  1.9450e-03, -9.8244e-02,  2.5278e-02, -4.0542e-02,\n",
       "        -5.0059e-33, -3.3913e-02, -1.3407e-02, -1.3561e-02,  6.4669e-02,\n",
       "        -7.8176e-03, -6.3043e-03, -7.0788e-03,  1.2799e-02, -6.8822e-02,\n",
       "        -2.6029e-02, -4.4970e-02, -2.0740e-02,  2.8443e-02,  5.5322e-02,\n",
       "         2.9002e-02, -3.2090e-02, -1.4916e-02,  1.1325e-02,  5.5595e-02,\n",
       "        -4.0812e-02, -2.1100e-02,  4.7727e-02,  7.8153e-02,  5.2969e-02,\n",
       "         6.5753e-02,  1.4473e-02, -2.1859e-02, -4.4025e-02,  2.4133e-02,\n",
       "        -2.3135e-02,  1.9605e-03,  1.0089e-02,  5.4928e-04, -3.5436e-02,\n",
       "         5.6197e-02, -6.8405e-02, -2.3612e-02, -2.6677e-02, -9.2318e-02,\n",
       "         1.6114e-02, -4.8029e-02,  2.5985e-02,  7.7183e-03, -9.9038e-03,\n",
       "        -2.0312e-02, -3.5363e-03,  1.2996e-02,  1.2751e-02, -3.7514e-02,\n",
       "        -5.0622e-02,  1.8883e-02, -2.0253e-03, -1.3546e-02,  3.3231e-02,\n",
       "        -9.5451e-02,  7.4038e-02,  1.0986e-02, -1.9255e-02,  4.7665e-03,\n",
       "         5.8193e-03, -9.5840e-03,  4.0239e-02, -4.5270e-02,  3.4707e-03,\n",
       "         8.1519e-02,  4.2620e-02,  2.9432e-03,  8.5297e-03,  4.7345e-02,\n",
       "        -2.3075e-02, -9.0513e-03,  3.1871e-02, -1.8030e-02, -3.5084e-03,\n",
       "         6.0108e-02, -7.5136e-03,  3.7627e-02,  3.3201e-02,  4.6167e-02,\n",
       "        -1.6150e-02, -3.5014e-02, -2.2554e-02, -3.9473e-02,  2.2777e-02,\n",
       "        -2.7032e-02,  3.3918e-02,  4.1890e-02, -2.4798e-02,  1.1404e-02,\n",
       "         3.8167e-02, -1.1141e-02,  3.1487e-02, -1.5654e-02, -3.4466e-02,\n",
       "         4.6647e-03,  2.6762e-02,  3.3781e-02,  2.0912e-02, -2.6165e-02,\n",
       "         4.1980e-02,  2.4704e-02, -3.9990e-02, -3.0237e-02, -2.8763e-02,\n",
       "        -4.2433e-02,  2.8761e-02, -4.0161e-02,  2.3959e-02,  1.9046e-02,\n",
       "         3.2569e-03,  4.3781e-03,  6.3699e-03,  9.9347e-03,  3.9999e-02,\n",
       "        -5.2804e-02, -5.2027e-02, -3.3560e-04, -3.4896e-02, -3.4897e-02,\n",
       "         4.9782e-02,  5.7338e-02,  1.7766e-02, -5.3342e-03, -1.5127e-02,\n",
       "        -2.7512e-02, -5.2076e-02, -3.6951e-02, -2.4592e-02, -3.9806e-02,\n",
       "        -5.4159e-02,  3.2962e-03,  6.0617e-02,  2.1152e-07,  5.1110e-03,\n",
       "         1.6629e-03,  1.2947e-02,  6.2298e-02,  3.3143e-02,  6.8569e-02,\n",
       "         2.5059e-02, -3.2076e-02, -1.0304e-02, -4.2584e-02, -3.8583e-02,\n",
       "         1.2298e-02, -9.1994e-03,  4.1684e-02, -7.6975e-03, -1.6703e-02,\n",
       "        -1.3279e-02, -7.6827e-03, -8.8850e-03, -1.6587e-02,  2.6483e-02,\n",
       "         5.5562e-02, -1.7134e-02,  1.7553e-02, -1.4942e-02, -7.2983e-02,\n",
       "         2.0389e-02, -5.6606e-02, -2.1825e-02, -4.0249e-02, -7.7185e-02,\n",
       "         5.1571e-02,  1.6265e-02, -7.2162e-02,  3.6374e-03,  4.0053e-03,\n",
       "         2.1421e-03, -2.5696e-02, -8.6988e-03, -1.0652e-02,  2.4780e-02,\n",
       "        -6.0157e-02,  1.6322e-02, -2.7406e-02,  1.2621e-02, -1.3869e-02,\n",
       "        -2.4589e-02,  2.2756e-03,  1.5050e-03,  3.9013e-02,  1.4689e-03,\n",
       "        -1.5580e-02, -1.7118e-02, -2.5775e-02,  1.7091e-02,  5.0574e-03,\n",
       "        -1.5930e-02,  3.8224e-02, -6.3820e-03, -4.9453e-02, -5.9849e-02,\n",
       "         2.5643e-02,  8.9973e-03,  8.9498e-02, -1.9516e-02,  2.0038e-02,\n",
       "         2.6874e-02,  7.2359e-35,  8.6814e-03, -5.9221e-02,  8.9814e-03,\n",
       "         3.1201e-03,  2.2492e-02,  3.9347e-02,  3.2214e-02,  6.8560e-03,\n",
       "         3.9575e-03,  1.5971e-02, -3.9374e-03], device='mps:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = model.encode(query, show_progress_bar=True, convert_to_tensor=True)\n",
    "query_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4349]], device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(query_embeddings, corpus_embeddings[0])\n",
    "# query and corpus[0] is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0232]], device='mps:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(query_embeddings, corpus_embeddings[9])\n",
    "# query and corpus[9] is not similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 2, 'score': 0.48030221462249756},\n",
       " {'corpus_id': 0, 'score': 0.4349438548088074},\n",
       " {'corpus_id': 4, 'score': 0.3824135363101959},\n",
       " {'corpus_id': 5, 'score': 0.3790991008281708},\n",
       " {'corpus_id': 3, 'score': 0.3513832986354828},\n",
       " {'corpus_id': 1, 'score': 0.0936562716960907},\n",
       " {'corpus_id': 6, 'score': 0.08781059086322784},\n",
       " {'corpus_id': 7, 'score': 0.07335850596427917},\n",
       " {'corpus_id': 8, 'score': 0.020925577729940414},\n",
       " {'corpus_id': 9, 'score': -0.023243635892868042}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = util.semantic_search(query_embeddings, corpus_embeddings)[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 | How I sleep knowing etherum is going to 10k in 2023\n",
      "0.43 | #Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\n",
      "0.38 | IS THE $BTC BOTTOM IN? Are you team BULL or team BEAR? Do you have the DATA to prove your point??\n",
      "0.38 | I will stop bragging about calling the top when I start bragging about calling the bottom. #bitcoin\n",
      "0.35 | Bitcoin is a scam\n",
      "0.09 | One of the biggest Bull traps I've ever seen.\n",
      "0.09 | First powerlifting meet of the year and a new squat PR!!\n",
      "0.07 | On January 9th, 2023, the American Academy of Pediatrics published new guidelines treating obesity in children and adolescents.\n",
      "0.02 | What's worse, someone dropping the bar from the top of a deadlift or not putting their shopping cart away?\n",
      "-0.02 | The sport of powerlifting includes squat bench and deadlift. But the concept of powerlifting is Force= Mass x Acceleration.\n"
     ]
    }
   ],
   "source": [
    "for item in result:\n",
    "    print(round(item[\"score\"], 2), \"|\", corpus[item[\"corpus_id\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try with another query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"How much should I deadlift at 82 kg bodyweight?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.2256e-02,  1.1967e-03,  8.6330e-03, -1.2649e-02,  1.1034e-02,\n",
       "         1.6971e-02,  4.3388e-03, -7.4748e-03,  5.4104e-02,  1.9416e-03,\n",
       "         2.5907e-02, -1.1454e-02, -1.6992e-02,  3.5316e-02,  7.2062e-03,\n",
       "         6.2534e-02,  2.5968e-02, -3.7030e-02,  7.0303e-03, -4.8572e-02,\n",
       "        -2.5945e-02, -5.3107e-02,  1.3602e-03, -1.9749e-02,  2.3767e-02,\n",
       "         3.3390e-02,  2.5558e-03, -2.1845e-03, -1.3981e-02, -1.0333e-02,\n",
       "        -5.7795e-02, -4.4480e-02,  3.1190e-02,  2.0615e-02,  1.4621e-06,\n",
       "        -2.4923e-03,  6.9576e-02, -3.5369e-02, -3.9735e-03,  3.4671e-02,\n",
       "        -4.9421e-02,  6.6175e-03,  4.1269e-02, -4.8071e-02, -6.1899e-04,\n",
       "        -5.0947e-02,  1.4739e-02, -6.6379e-03,  1.8297e-02,  3.6581e-02,\n",
       "         1.1360e-02, -1.5486e-02,  2.8479e-02,  3.3475e-02, -2.0449e-02,\n",
       "        -9.6084e-03, -2.0978e-02,  8.7421e-02, -5.1352e-02,  5.5530e-02,\n",
       "        -1.1669e-02,  3.1585e-02, -6.1537e-03,  3.7862e-02, -4.0668e-02,\n",
       "        -7.3277e-04, -2.3658e-02,  1.3450e-02,  4.0673e-02,  5.5164e-02,\n",
       "        -4.9294e-02,  5.8277e-02, -2.7763e-02,  2.4577e-02, -1.6455e-03,\n",
       "        -1.2309e-02,  2.2490e-02,  6.1808e-03,  1.3009e-02,  7.7639e-03,\n",
       "         2.3020e-02,  1.9520e-02,  1.1701e-02, -7.6255e-03,  7.6853e-03,\n",
       "         2.0231e-02, -1.7865e-02,  1.8258e-02,  7.0408e-02, -4.8040e-02,\n",
       "        -8.4786e-02, -3.3011e-02,  2.2510e-02,  3.7662e-03, -3.7089e-02,\n",
       "         2.6178e-02,  6.0030e-02, -3.2850e-02, -7.1470e-03, -5.1799e-03,\n",
       "        -2.6339e-02,  1.9578e-02,  2.4177e-02, -2.8597e-02, -1.0536e-02,\n",
       "        -3.7325e-02,  1.2244e-02, -4.0512e-02, -3.6493e-02,  2.4471e-02,\n",
       "        -4.4110e-02,  1.1044e-02, -2.1604e-02,  1.5784e-02,  3.7331e-02,\n",
       "        -3.2947e-02, -4.1260e-02, -3.3798e-02,  1.7923e-02, -9.0164e-02,\n",
       "         2.9595e-02,  1.4170e-02, -1.4521e-02,  1.4622e-03,  5.0301e-02,\n",
       "         5.3564e-02, -3.4757e-02,  2.9352e-02,  2.9136e-02, -3.1006e-02,\n",
       "         5.2579e-03, -2.3574e-02,  5.0467e-02, -4.7667e-02,  2.6230e-02,\n",
       "        -4.0075e-02,  8.3293e-03,  3.4016e-03,  4.2942e-02, -5.2765e-02,\n",
       "        -2.5066e-02,  2.7202e-02, -2.4050e-02, -2.4022e-02, -2.2598e-03,\n",
       "        -1.7462e-02, -2.3553e-02,  3.0427e-02,  6.8124e-03,  5.8793e-02,\n",
       "        -3.3119e-02,  2.2025e-02,  3.2540e-02,  9.7834e-02,  3.6512e-02,\n",
       "        -5.6937e-02, -6.2965e-02,  4.1690e-03,  1.6620e-02,  3.9383e-02,\n",
       "        -8.0600e-03,  7.4331e-02, -1.3388e-02, -3.9426e-02, -2.6437e-02,\n",
       "         4.9701e-02, -4.9458e-02, -6.2584e-03, -1.9420e-02,  2.7702e-02,\n",
       "        -7.1445e-02,  1.2337e-02, -4.0087e-02,  4.2099e-02,  1.7382e-02,\n",
       "         8.2275e-03, -2.9882e-02, -6.4261e-02, -9.4246e-03,  8.8810e-03,\n",
       "         7.0408e-03, -9.2600e-02, -2.0748e-02, -1.5876e-02,  2.2238e-02,\n",
       "         3.0262e-03, -1.5741e-02,  1.9656e-02, -3.2848e-03,  2.9227e-02,\n",
       "         2.0121e-02, -1.0379e-02,  1.6257e-02, -2.1107e-02,  5.8440e-02,\n",
       "         1.5497e-02, -4.4058e-02, -3.9367e-02, -6.7375e-03, -4.3900e-02,\n",
       "         5.0908e-03, -5.2153e-02, -4.6792e-03, -7.4209e-02,  3.1504e-02,\n",
       "         3.8103e-02, -2.1761e-02,  1.4325e-02,  1.0479e-01, -7.2014e-03,\n",
       "         1.6432e-03,  5.3455e-02,  3.6100e-02,  5.9527e-03, -6.5810e-02,\n",
       "        -5.8254e-02, -2.4029e-02, -4.9710e-02, -4.2806e-02, -2.9690e-02,\n",
       "        -2.6920e-02, -4.1534e-02, -4.2410e-02,  2.8625e-02, -2.6313e-02,\n",
       "         1.5413e-02,  3.2503e-03, -3.2845e-03, -1.8521e-02, -1.1640e-02,\n",
       "         4.1907e-03, -1.3380e-02, -1.0127e-02,  1.3274e-02, -3.8656e-02,\n",
       "         6.1140e-02,  4.8500e-02, -8.0830e-03,  2.3801e-02, -1.1280e-02,\n",
       "         3.5487e-02, -5.5766e-03,  3.4870e-02, -5.9960e-02,  1.4464e-02,\n",
       "         6.0641e-04,  3.7744e-02,  7.4211e-03,  9.5789e-03,  3.4855e-02,\n",
       "        -3.3017e-02, -2.5878e-02,  5.2467e-02,  5.9603e-02, -1.3676e-02,\n",
       "         1.3123e-02, -8.9187e-02, -1.2520e-02, -3.9805e-02, -4.8838e-02,\n",
       "        -3.5476e-02, -3.9804e-02,  5.9041e-04, -1.8165e-02,  7.7454e-02,\n",
       "         9.2867e-03,  3.6930e-02, -5.8596e-02,  6.0364e-02, -3.8517e-03,\n",
       "         2.5903e-02, -2.0996e-02,  6.0685e-02, -2.6610e-02, -6.6527e-02,\n",
       "        -5.1258e-02,  2.9487e-02, -6.0635e-02, -5.2047e-02, -1.8194e-02,\n",
       "         4.2818e-03,  2.3727e-02,  1.1406e-02,  4.5507e-02,  1.6022e-02,\n",
       "        -2.1538e-02,  5.7003e-02,  1.6088e-02,  3.0894e-02,  2.5400e-02,\n",
       "         9.7594e-02,  5.6339e-02, -2.8064e-03, -9.5647e-02,  5.2332e-03,\n",
       "         3.4953e-02,  1.9704e-02, -4.8248e-02,  7.1122e-04, -2.7846e-02,\n",
       "         3.1574e-02,  5.5091e-02, -9.4822e-03,  7.9694e-03, -7.8422e-02,\n",
       "        -2.7857e-02, -6.6634e-03,  2.5297e-02,  3.3905e-02,  4.6825e-02,\n",
       "         1.5302e-03, -7.2848e-03,  6.6320e-03, -5.1385e-02, -4.4326e-02,\n",
       "         3.8042e-02,  1.4711e-02, -3.5715e-02, -6.5434e-03,  6.7100e-03,\n",
       "        -6.3845e-04,  2.6445e-02, -1.9054e-03,  3.9341e-02,  4.2659e-02,\n",
       "         4.5012e-02, -2.2162e-02,  1.6899e-03, -3.2254e-02, -2.1230e-02,\n",
       "        -1.3754e-02, -1.7910e-02,  2.1160e-02, -2.6249e-02,  3.7364e-02,\n",
       "        -1.2523e-02,  1.9761e-02, -3.8523e-02, -3.7272e-02,  6.8487e-02,\n",
       "         1.5550e-02, -1.7562e-03, -1.9509e-03,  4.0645e-02, -2.1750e-02,\n",
       "        -2.7407e-02, -7.2986e-02,  1.9875e-02,  9.5256e-03, -2.9753e-02,\n",
       "         7.3894e-03, -4.8140e-03, -4.2213e-02, -5.2690e-02, -3.6843e-02,\n",
       "         6.1779e-03,  1.7504e-02,  8.2273e-02, -5.0559e-02,  4.3725e-03,\n",
       "         4.3672e-03, -5.5066e-02,  1.1582e-05,  2.5992e-02, -4.7126e-02,\n",
       "        -1.6524e-02,  2.8960e-02, -3.3323e-02,  2.6209e-02, -2.7783e-02,\n",
       "         5.9393e-02,  5.6427e-02, -5.4094e-02, -3.2101e-02, -4.8100e-03,\n",
       "        -1.9739e-02, -7.8103e-03, -2.8216e-02, -6.4657e-02,  8.8270e-03,\n",
       "        -7.1487e-03,  1.8199e-02, -6.0471e-02, -1.5102e-03,  7.4430e-02,\n",
       "        -9.3139e-03,  4.6079e-02,  3.6572e-02, -3.2556e-02, -7.7127e-02,\n",
       "        -4.8186e-02, -3.6087e-02, -2.7133e-02,  3.3949e-02, -3.3694e-02,\n",
       "        -6.5212e-02, -3.6372e-02,  5.7655e-02, -1.5240e-03,  6.7154e-02,\n",
       "        -8.9351e-03, -1.5035e-02, -6.9385e-03,  3.1996e-02, -5.4350e-02,\n",
       "         2.2123e-02,  1.7702e-02,  6.1651e-02, -2.3176e-02, -4.6320e-02,\n",
       "         6.3487e-02, -9.9304e-02, -6.6595e-02, -1.2969e-02,  2.3176e-02,\n",
       "         1.4086e-03, -2.7363e-02, -2.3081e-02,  2.6013e-02, -4.3277e-02,\n",
       "        -2.4766e-02,  2.5514e-02, -4.1580e-02, -2.5732e-02,  5.6964e-03,\n",
       "        -3.5131e-03,  1.8068e-02, -9.6202e-03, -4.9102e-03, -2.2106e-02,\n",
       "        -1.8443e-02, -3.9479e-03, -2.4178e-02,  6.8183e-02, -2.2398e-02,\n",
       "         5.8181e-02, -2.8249e-02, -5.5264e-02,  1.2699e-01,  5.1733e-02,\n",
       "         3.0115e-02, -1.3472e-02, -3.2766e-03, -1.3021e-02,  2.2891e-02,\n",
       "        -1.3594e-02, -1.8693e-02, -6.3172e-03,  1.3125e-02, -1.2398e-02,\n",
       "         8.3254e-04,  3.9496e-02, -5.7925e-02,  7.8883e-02,  3.7149e-02,\n",
       "         2.7955e-02, -2.0918e-02,  4.3443e-02,  4.9526e-02, -2.9434e-02,\n",
       "         6.6336e-03,  2.0305e-02, -5.7722e-02,  5.7425e-03, -1.9199e-02,\n",
       "        -1.0883e-02,  5.0472e-02, -8.4746e-02, -9.6326e-03, -4.1749e-02,\n",
       "        -1.0842e-02,  1.6394e-02,  2.6168e-02, -2.7686e-02,  2.3248e-02,\n",
       "         5.2861e-02,  1.8149e-02, -2.5581e-02, -2.0427e-02, -6.1050e-03,\n",
       "         4.0057e-02, -1.1504e-03, -6.9574e-03, -3.3208e-02, -3.9404e-02,\n",
       "         2.7373e-02,  3.9122e-02,  3.9260e-02, -3.1212e-02, -2.8478e-03,\n",
       "        -2.6237e-02, -2.5194e-04,  2.6413e-02,  6.1190e-02,  3.3075e-02,\n",
       "         2.7748e-02, -2.1118e-02, -5.5688e-02, -2.0412e-02,  3.6900e-02,\n",
       "        -3.5894e-03, -5.0636e-02, -2.1215e-02, -3.4424e-02, -4.3456e-02,\n",
       "        -2.1527e-02, -1.5104e-03, -7.5107e-02, -3.5039e-02, -5.4767e-02,\n",
       "        -1.2897e-02,  2.2249e-02, -3.8701e-03,  4.7753e-02,  4.8506e-03,\n",
       "        -3.6381e-02, -1.9080e-02, -3.8201e-02,  3.7870e-02,  2.3533e-02,\n",
       "         3.5202e-02, -2.4670e-02,  2.0315e-02, -5.7441e-03,  4.5210e-02,\n",
       "         1.2429e-02, -3.3306e-02, -5.6155e-02, -1.1812e-03,  1.9766e-03,\n",
       "        -6.5160e-03, -1.1796e-02,  2.6195e-02, -4.2513e-03,  1.1523e-02,\n",
       "         4.1564e-02,  8.1040e-02,  5.9208e-02, -1.1323e-02,  3.5855e-02,\n",
       "         1.1531e-02, -3.7824e-04, -1.7438e-02,  4.4262e-02, -7.7984e-03,\n",
       "         4.3618e-02,  1.1754e-02, -1.8456e-02,  5.8987e-02,  7.7248e-03,\n",
       "        -5.9164e-03,  2.9676e-02,  2.1197e-03,  5.9070e-02,  5.8305e-02,\n",
       "        -4.7689e-33,  1.7039e-02,  3.2569e-02,  1.3004e-02,  7.1940e-02,\n",
       "         1.8608e-02,  4.2508e-02,  2.4443e-02, -2.6806e-02, -3.7421e-03,\n",
       "         5.2027e-03,  7.1925e-03,  5.8132e-03,  4.7039e-03, -5.7463e-02,\n",
       "        -1.4414e-02, -6.0257e-04, -6.1044e-02,  2.5224e-02, -1.4326e-02,\n",
       "        -3.0041e-02, -4.2060e-02, -3.9914e-02,  3.2882e-02,  7.2489e-02,\n",
       "        -2.2439e-02,  2.9451e-02, -2.8824e-02, -4.7218e-02, -3.7706e-02,\n",
       "        -5.0709e-02, -5.9153e-02,  5.2360e-02, -1.8046e-02,  3.9871e-02,\n",
       "        -7.4191e-03, -4.1488e-02,  1.4483e-02, -4.8973e-02, -3.1927e-02,\n",
       "        -1.7644e-02, -4.2856e-02,  6.3566e-04,  6.1546e-02,  2.1685e-02,\n",
       "        -6.3642e-02, -1.6016e-02,  6.3299e-02,  4.7642e-02,  1.7458e-02,\n",
       "         1.0125e-03,  3.4395e-02,  3.7846e-02,  6.9150e-02,  1.5480e-02,\n",
       "         2.9339e-02, -3.3969e-03, -1.2887e-02, -5.4875e-02,  4.9136e-02,\n",
       "        -1.1458e-01, -1.6022e-02, -6.4960e-02, -1.7807e-02, -1.0197e-02,\n",
       "         1.7591e-02,  2.0598e-03, -2.8526e-02, -1.2118e-02,  6.7790e-02,\n",
       "        -1.2638e-02,  3.6810e-02,  9.9248e-03, -3.4607e-02, -9.8063e-04,\n",
       "         9.0793e-02,  1.3191e-03, -4.5920e-02,  2.2361e-02,  8.3334e-02,\n",
       "         7.6361e-02, -4.8483e-02, -1.9445e-02,  5.6455e-02,  1.7668e-02,\n",
       "         4.8976e-03,  3.5803e-02, -2.9848e-02, -4.4324e-02,  2.2593e-02,\n",
       "         2.2877e-02, -1.0235e-02,  2.7382e-02, -2.8176e-03,  3.7259e-03,\n",
       "        -5.7675e-03, -1.1505e-02, -4.2958e-03,  2.1614e-02,  1.5282e-02,\n",
       "        -3.2822e-02,  8.0324e-02, -5.1002e-02,  1.8355e-02, -1.8201e-02,\n",
       "         2.7530e-02,  1.1830e-02,  1.9987e-02, -8.6686e-03, -1.7439e-03,\n",
       "        -1.4120e-02, -1.9982e-02, -3.1619e-02, -1.3100e-02,  2.3348e-02,\n",
       "         2.1286e-02,  5.2533e-02, -3.9210e-02, -1.4598e-02, -5.0535e-02,\n",
       "        -1.9667e-02, -1.3064e-02, -2.7646e-02,  2.5819e-02, -9.1553e-03,\n",
       "        -6.3286e-03, -4.0957e-02,  5.3559e-02, -2.7093e-02, -7.9321e-02,\n",
       "        -1.0488e-02, -2.6386e-02,  1.0947e-02,  1.9909e-07,  2.6135e-02,\n",
       "        -7.6748e-03,  6.9307e-03,  8.6519e-02, -5.8849e-02,  9.7631e-04,\n",
       "        -3.0947e-03,  5.9043e-02,  3.6993e-02, -2.0503e-02, -2.4764e-02,\n",
       "         2.9234e-02, -6.7032e-02, -3.3334e-02,  6.9106e-03,  4.1406e-02,\n",
       "        -8.8864e-03,  5.3398e-02, -7.4515e-03,  2.7038e-02, -4.0285e-02,\n",
       "         4.3286e-02,  2.5584e-02,  8.9406e-04,  2.9745e-04,  2.8160e-02,\n",
       "         1.2011e-03, -3.1809e-02, -3.2318e-02, -4.7788e-02,  4.0502e-02,\n",
       "        -2.1686e-02,  4.9589e-02,  6.0836e-02, -9.9576e-03, -9.5598e-03,\n",
       "         4.3281e-02,  5.3047e-02, -3.1277e-02,  3.7147e-02,  3.2820e-02,\n",
       "         2.6619e-03,  2.6460e-02,  4.6155e-02,  3.0420e-02, -1.6052e-02,\n",
       "         6.2925e-03, -4.0531e-02, -2.6123e-02, -6.3723e-03,  8.8367e-03,\n",
       "        -5.0639e-02,  7.1658e-02,  4.3085e-02,  2.4871e-02, -7.7494e-03,\n",
       "         3.0747e-03,  1.4664e-02, -1.3355e-02, -5.8813e-02,  1.8513e-03,\n",
       "         5.4465e-03, -3.2787e-02,  5.3686e-02, -1.6461e-02, -4.4647e-02,\n",
       "         2.0008e-02,  9.3349e-35, -4.5239e-02,  1.4937e-02, -3.8085e-03,\n",
       "        -3.0670e-03, -3.8262e-02,  6.6929e-05,  1.0776e-02,  5.2175e-02,\n",
       "        -1.7514e-02, -1.7982e-02,  3.1548e-02], device='mps:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2_embeddings = model.encode(query_2, show_progress_bar=True, convert_to_tensor=True)\n",
    "query2_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 9, 'score': 0.32635003328323364},\n",
       " {'corpus_id': 8, 'score': 0.24540135264396667},\n",
       " {'corpus_id': 6, 'score': 0.13916906714439392},\n",
       " {'corpus_id': 7, 'score': 0.10069739818572998},\n",
       " {'corpus_id': 2, 'score': 0.047277357429265976},\n",
       " {'corpus_id': 0, 'score': 0.030338570475578308},\n",
       " {'corpus_id': 4, 'score': 0.01547253131866455},\n",
       " {'corpus_id': 5, 'score': 0.009970581158995628},\n",
       " {'corpus_id': 3, 'score': -0.015322110615670681},\n",
       " {'corpus_id': 1, 'score': -0.042820487171411514}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = util.semantic_search(query2_embeddings, corpus_embeddings)[0]\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33 | The sport of powerlifting includes squat bench and deadlift. But the concept of powerlifting is Force= Mass x Acceleration.\n",
      "0.25 | What's worse, someone dropping the bar from the top of a deadlift or not putting their shopping cart away?\n",
      "0.14 | First powerlifting meet of the year and a new squat PR!!\n",
      "0.1 | On January 9th, 2023, the American Academy of Pediatrics published new guidelines treating obesity in children and adolescents.\n",
      "0.05 | How I sleep knowing etherum is going to 10k in 2023\n",
      "0.03 | #Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\n",
      "0.02 | IS THE $BTC BOTTOM IN? Are you team BULL or team BEAR? Do you have the DATA to prove your point??\n",
      "0.01 | I will stop bragging about calling the top when I start bragging about calling the bottom. #bitcoin\n",
      "-0.02 | Bitcoin is a scam\n",
      "-0.04 | One of the biggest Bull traps I've ever seen.\n"
     ]
    }
   ],
   "source": [
    "for item in result_2:\n",
    "    print(round(item[\"score\"], 2), \"|\", corpus[item[\"corpus_id\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\"\n",
    "sentence_2 = \"One of the biggest Bull traps I've ever seen.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to make the embeddings of the above two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence1_embeddings = model.encode(sentence_1, show_progress_bar=True, convert_to_tensor=True)\n",
    "sentence2_embeddings = model.encode(sentence_2, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(sentence1_embeddings.shape)\n",
    "print(sentence2_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1469]], device='mps:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(sentence1_embeddings, sentence2_embeddings)\n",
    "# The two sentences is similar but according to the model these are not similar as you can see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/My Drive/Hassan USB Data/Bytewise NLP/env/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentencesDataset, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device='cpu')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentencesDataset([\n",
    "    InputExample(\n",
    "        texts=[\n",
    "            \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\"\n",
    "            \"One of the biggest Bull traps I've ever seen.\"\n",
    "        ], label=0.9\n",
    "    )\n",
    "], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1129cbcd0>\n",
      "CosineSimilarityLoss(\n",
      "  (model): SentenceTransformer(\n",
      "    (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "    (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "    (2): Normalize()\n",
      "  )\n",
      "  (loss_fct): MSELoss()\n",
      "  (cos_score_transformation): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=int(16))\n",
    "print(dataloader)\n",
    "\n",
    "loss = losses.CosineSimilarityLoss(model=model)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_path = \"trained_model\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_objectives=[(dataloader, loss)], \n",
    "          epochs=10,\n",
    "          warmup_steps=10,\n",
    "          output_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/My Drive/Hassan USB Data/Bytewise NLP/env/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/owner/My Drive/Hassan USB Data/Bytewise NLP/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Number of batches: 1\n",
      "CosineSimilarityLoss(\n",
      "  (model): SentenceTransformer(\n",
      "    (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "    (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "    (2): Normalize()\n",
      "  )\n",
      "  (loss_fct): MSELoss()\n",
      "  (cos_score_transformation): Identity()\n",
      ")\n",
      "Texts: [[\"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\", \"One of the biggest Bull traps I've ever seen.\"]]\n",
      "Labels shape: torch.Size([1]), Type: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9.8525, 'train_samples_per_second': 1.015, 'train_steps_per_second': 1.015, 'train_loss': 0.3232328653335571, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Load model with MPS (Metal Performance Shaders) support\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "print(model)\n",
    "\n",
    "# Prepare dataset with multiple examples\n",
    "dataset = SentencesDataset([\n",
    "    InputExample(\n",
    "        texts=[\n",
    "            \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\",\n",
    "            \"One of the biggest Bull traps I've ever seen.\"\n",
    "        ],\n",
    "        label=0.9,\n",
    "    ),\n",
    "], model)\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    texts = [example.texts for example in batch]\n",
    "    labels = torch.tensor([example.label for example in batch], dtype=torch.float)\n",
    "    return texts, labels\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "# Initialize DataLoader with a smaller batch size and custom collate function\n",
    "dataloader = DataLoader(dataset, shuffle=True, collate_fn=collate_fn)\n",
    "print(f\"Number of batches: {len(dataloader)}\")\n",
    "\n",
    "# Define loss function\n",
    "loss = losses.CosineSimilarityLoss(model=model)\n",
    "print(loss)\n",
    "\n",
    "# Print shapes and types of the first batch\n",
    "for batch in dataloader:\n",
    "    print(f\"Texts: {batch[0]}\")\n",
    "    print(f\"Labels shape: {batch[1].shape}, Type: {batch[1].dtype}\")\n",
    "    break\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(dataloader, loss)], \n",
    "          epochs=10, \n",
    "          warmup_steps=10, \n",
    "          output_path=\"trained_model\")\n",
    "\n",
    "print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/My Drive/Hassan USB Data/Bytewise NLP/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8.7875, 'train_samples_per_second': 1.138, 'train_steps_per_second': 1.138, 'train_loss': 0.3232328653335571, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "print(model)\n",
    "\n",
    "# Prepare dataset\n",
    "train_examples = [\n",
    "    InputExample(texts=[\n",
    "        \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\",\n",
    "        \"One of the biggest Bull traps I've ever seen.\"\n",
    "        ], label=0.9),\n",
    "]\n",
    "\n",
    "train_dataset = CustomDataset(train_examples)\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "\n",
    "# Use the default train() method\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "import os\n",
    "save_path = \"trained_model\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=10,\n",
    "    warmup_steps=10,\n",
    "    output_path=save_path\n",
    ")\n",
    "\n",
    "print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of our trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s]\n"
     ]
    }
   ],
   "source": [
    "trained_model = SentenceTransformer(\"trained_model\")\n",
    "\n",
    "sentence_1 = \"#Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and Crypto.'\"\n",
    "sentence_2 = \"One of the biggest Bull traps I've ever seen.\"\n",
    "\n",
    "sentence1_embeddings = model.encode(sentence_1, show_progress_bar=True, convert_to_tensor=True)\n",
    "sentence2_embeddings = model.encode(sentence_2, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8297]], device='mps:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(sentence1_embeddings, sentence2_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
